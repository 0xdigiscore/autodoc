{
  "folderName": "commands",
  "folderPath": ".autodoc/docs/json/src/cli/commands",
  "url": "https://github.com/context-labs/autodoc/tree/master/.autodoc/docs/json/src/cli/commands",
  "files": [],
  "folders": [
    {
      "folderName": "estimate",
      "folderPath": ".autodoc/docs/json/src/cli/commands/estimate",
      "url": "https://github.com/context-labs/autodoc/tree/master/.autodoc/docs/json/src/cli/commands/estimate",
      "files": [
        {
          "fileName": "index.ts",
          "filePath": "src/cli/commands/estimate/index.ts",
          "url": "https://github.com/context-labs/autodoc/blob/master/src/cli/commands/estimate/index.ts",
          "summary": "The `estimate` function in this file is a part of the larger autodoc project and is responsible for estimating the cost of indexing a given repository. The function takes in an object with several properties including the name of the repository, its URL, the root directory, the output directory, and some other optional parameters. \n\nThe function first sets the path for the output directory where the JSON files will be stored. It then runs a dry run of the `processRepository` command to estimate the cost of indexing the repository. The `processRepository` function is imported from the `processRepository.js` file located in the `index` directory. It takes in an object with the same properties as the `estimate` function and a boolean value indicating whether it should be a dry run or not. The function returns an object with details about the models that will be created during the indexing process.\n\nOnce the `processRepository` function has completed, the `estimate` function prints the details of the models that will be created and the estimated cost of indexing the repository. The `printModelDetails` function is imported from the `LLMUtil.js` file located in the `utils` directory and takes in an array of objects representing the models. The `totalIndexCostEstimate` function is also imported from the same file and takes in the same array of objects. It calculates the total cost of indexing the repository based on the estimated cost of each model.\n\nFinally, the function logs the estimated cost to the console using the `chalk` library to color the output. It reminds the user that the estimate is just an estimate and that the actual cost may vary. It also recommends setting a limit in the OpenAI account to prevent unexpected charges.\n\nOverall, the `estimate` function provides a convenient way for users of the autodoc project to estimate the cost of indexing a repository before actually doing so. This can help users make informed decisions about whether or not to proceed with the indexing process. \n\nExample usage:\n\n```\nimport { estimate } from 'autodoc';\n\nestimate({\n  name: 'my-repo',\n  repositoryUrl: 'https://github.com/my-username/my-repo.git',\n  root: '/path/to/repo',\n  output: '/path/to/output',\n  llms: true,\n  ignore: ['node_modules', 'dist'],\n});\n```",
          "questions": "1. What is the purpose of this code?\n   - This code is used to estimate the cost of indexing a repository for the Autodoc project.\n2. What dependencies does this code use?\n   - This code uses several dependencies including `path`, `chalk`, and custom modules from the `../../spinner.js`, `../index/processRepository.js`, and `../../utils/LLMUtil.js` files.\n3. What input parameters does the `estimate` function expect?\n   - The `estimate` function expects an object with properties `name`, `repositoryUrl`, `root`, `output`, `llms`, and `ignore`, all of which are of type `AutodocRepoConfig`."
        }
      ],
      "folders": [],
      "summary": "The `estimate` function in `index.ts` is designed to estimate the cost of indexing a given repository within the autodoc project. It takes an object with properties such as the repository name, URL, root directory, output directory, and optional parameters.\n\n```javascript\nimport { estimate } from 'autodoc';\n\nestimate({\n  name: 'my-repo',\n  repositoryUrl: 'https://github.com/my-username/my-repo.git',\n  root: '/path/to/repo',\n  output: '/path/to/output',\n  llms: true,\n  ignore: ['node_modules', 'dist'],\n});\n```\n\nThe function sets the output directory path and runs a dry run of the `processRepository` command to estimate the indexing cost. The `processRepository` function is imported from the `processRepository.js` file and takes an object with the same properties as the `estimate` function, along with a boolean value for the dry run. It returns an object containing details about the models to be created during indexing.\n\nAfter the `processRepository` function completes, the `estimate` function prints the model details and the estimated indexing cost. The `printModelDetails` and `totalIndexCostEstimate` functions are imported from the `LLMUtil.js` file, both taking an array of objects representing the models. The latter calculates the total indexing cost based on each model's estimated cost.\n\nThe estimated cost is logged to the console using the `chalk` library for colored output. The function reminds users that the estimate is approximate and actual costs may vary. It also suggests setting a limit in the OpenAI account to avoid unexpected charges.\n\nIn summary, the `estimate` function offers a convenient way for autodoc users to estimate the cost of indexing a repository before proceeding, helping them make informed decisions about the indexing process.",
      "questions": ""
    },
    {
      "folderName": "index",
      "folderPath": ".autodoc/docs/json/src/cli/commands/index",
      "url": "https://github.com/context-labs/autodoc/tree/master/.autodoc/docs/json/src/cli/commands/index",
      "files": [
        {
          "fileName": "convertJsonToMarkdown.ts",
          "filePath": "src/cli/commands/index/convertJsonToMarkdown.ts",
          "url": "https://github.com/context-labs/autodoc/blob/master/src/cli/commands/index/convertJsonToMarkdown.ts",
          "summary": "The `convertJsonToMarkdown` function in the `autodoc` project is responsible for converting JSON files to markdown files. The function takes an object with three properties: `name`, `root`, and `output`. The `name` property is the name of the project, `root` is the root directory of the project, and `output` is the output directory where the markdown files will be created.\n\nThe function first counts the number of files in the project by calling the `traverseFileSystem` function from the `utils` module. The `traverseFileSystem` function recursively traverses the file system and calls the `processFile` function for each file. In this case, the `processFile` function increments the `files` variable for each file it processes.\n\nNext, the function creates a markdown file for each code file in the project by calling `traverseFileSystem` again. This time, the `processFile` function reads the content of the file, creates a markdown file with the same name in the output directory, and writes the markdown content to the file. The markdown content is generated from the JSON content of the file. If the file is a `summary.json` file, the content is parsed as a `FolderSummary` object, otherwise it is parsed as a `FileSummary` object. The `FolderSummary` and `FileSummary` objects have a `summary` property that contains a summary of the file, and an optional `questions` property that contains a list of questions related to the file. The markdown content includes a link to the file on GitHub, the summary, and the questions (if any).\n\nFinally, the function updates the spinner text to indicate that it is creating the markdown files, and then calls `traverseFileSystem` again to create the markdown files. Once all the files have been processed, the function updates the spinner text again to indicate that it has finished creating the markdown files.\n\nThis function can be used in the larger `autodoc` project to generate documentation for a project. The JSON files can be generated automatically by other parts of the project, and then passed to this function to generate the markdown files. The markdown files can then be used to generate HTML or PDF documentation.",
          "questions": "1. What is the purpose of the `convertJsonToMarkdown` function?\n    \n    The `convertJsonToMarkdown` function creates markdown files for each code file in a project, based on the summary and questions provided in JSON files.\n\n2. What is the `traverseFileSystem` function used for in this code?\n    \n    The `traverseFileSystem` function is used twice in this code to iterate through the files and folders in a project directory, and perform a specified action on each file.\n\n3. What is the purpose of the `getFileName` function?\n    \n    The `getFileName` function is used to modify the file path of a code file to create a corresponding markdown file path, by replacing the file extension with `.md`."
        },
        {
          "fileName": "createVectorStore.ts",
          "filePath": "src/cli/commands/index/createVectorStore.ts",
          "url": "https://github.com/context-labs/autodoc/blob/master/src/cli/commands/index/createVectorStore.ts",
          "summary": "The code in this file is responsible for creating a vector store for a set of documents. The vector store is a data structure that allows for efficient similarity search between documents based on their embeddings. The input to this code is a directory containing the documents to be indexed, and the output is a file containing the vector store.\n\nThe code first imports several modules from the `langchain` package, including the `OpenAIEmbeddings` class for generating document embeddings, the `RecursiveCharacterTextSplitter` class for splitting documents into smaller chunks, and the `Document` and `BaseDocumentLoader` classes for representing and loading documents, respectively. It also imports the `fs` module for reading files from disk, the `path` module for manipulating file paths, and the `AutodocRepoConfig` type for specifying the input and output directories.\n\nThe `processFile` function reads a file from disk and creates a `Document` object from its contents. The `processDirectory` function recursively processes all files in a directory, calling `processFile` on each file and `processDirectory` on each subdirectory. The resulting `Document` objects are collected into an array and returned.\n\nThe `RepoLoader` class extends `BaseDocumentLoader` and overrides its `load` method to call `processDirectory` on the input directory and return the resulting `Document` array.\n\nThe `createVectorStore` function is the main entry point for this code. It takes an `AutodocRepoConfig` object as input, which specifies the input and output directories. It creates a `RepoLoader` object with the input directory, loads all documents using the `load` method, splits the documents into smaller chunks using the `RecursiveCharacterTextSplitter`, generates embeddings for each chunk using `OpenAIEmbeddings`, and creates a vector store using `HNSWLib.fromDocuments`. Finally, it saves the vector store to the output file.\n\nHere is an example of how this code might be used:\n\n```typescript\nimport { createVectorStore } from 'autodoc';\n\nconst config = {\n  root: '/path/to/documents',\n  output: '/path/to/vectorstore.bin',\n};\n\ncreateVectorStore(config)\n  .then(() => console.log('Vector store created successfully'))\n  .catch((err) => console.error('Error creating vector store:', err));\n```\n\nThis code would create a vector store for all documents in the `/path/to/documents` directory and save it to the file `/path/to/vectorstore.bin`. If successful, it would log a success message to the console. If an error occurred, it would log an error message with the details of the error.",
          "questions": "1. What is the purpose of the `langchain` library and how is it used in this code?\n- A super smart developer might ask what the `langchain` library is and how it is being used in this code. \n- The `langchain` library is being used to import various modules such as `embeddings`, `text_splitter`, `document`, `document_loaders`, and `hnswlib`. These modules are used to process text documents and create a vector store.\n\n2. What is the purpose of the `processFile` and `processDirectory` functions?\n- A super smart developer might ask what the `processFile` and `processDirectory` functions do. \n- The `processFile` function reads a file from a given file path, creates a `Document` object with the file contents and metadata, and returns the `Document`. \n- The `processDirectory` function reads all files in a given directory path, recursively processes each file using `processFile`, and returns an array of `Document` objects.\n\n3. What is the purpose of the `createVectorStore` function and how is it used?\n- A super smart developer might ask what the `createVectorStore` function does and how it is used. \n- The `createVectorStore` function takes in an `AutodocRepoConfig` object with a `root` directory and an `output` file path, loads all documents in the `root` directory using `RepoLoader` and `processDirectory`, splits the text of each document into chunks using `RecursiveCharacterTextSplitter`, creates a vector store using `HNSWLib` and `OpenAIEmbeddings`, and saves the vector store to the `output` file path."
        },
        {
          "fileName": "index.ts",
          "filePath": "src/cli/commands/index/index.ts",
          "url": "https://github.com/context-labs/autodoc/blob/master/src/cli/commands/index/index.ts",
          "summary": "The code in this file is part of the Autodoc project and contains a function called `index` that serves as the entry point for generating documentation for a given repository. The function takes in an object with several properties, including the name of the repository, its URL, the root directory, and the output directory. \n\nThe `index` function first sets up the paths for the JSON, markdown, and data directories where the documentation will be stored. It then calls the `processRepository` function to traverse the repository, call the LLMS (Language Model Serving) for each file, and create JSON files with the results. The `updateSpinnerText` function is used to display a message indicating that the repository is being processed, and the `spinnerSuccess` function is called once the processing is complete.\n\nNext, the `convertJsonToMarkdown` function is called to create markdown files from the JSON files generated in the previous step. Again, the `updateSpinnerText` function is used to display a message indicating that markdown files are being created, and the `spinnerSuccess` function is called once the conversion is complete.\n\nFinally, the `createVectorStore` function is called to create vector files from the markdown files generated in the previous step. The `updateSpinnerText` function is used to display a message indicating that vector files are being created, and the `spinnerSuccess` function is called once the creation is complete.\n\nOverall, this code serves as a high-level interface for generating documentation for a given repository using Autodoc. It takes care of the entire process, from traversing the repository to creating vector files, and can be used as a standalone module or integrated into a larger project. \n\nExample usage:\n\n```\nimport autodoc from 'autodoc';\n\nconst config = {\n  name: 'my-repo',\n  repositoryUrl: 'https://github.com/my-username/my-repo',\n  root: '/path/to/my/repo',\n  output: '/path/to/output/directory',\n  llms: true,\n  ignore: ['node_modules', 'dist'],\n};\n\nautodoc.index(config);\n```",
          "questions": "1. What is the purpose of the `AutodocRepoConfig` type and where is it defined?\n- The `AutodocRepoConfig` type is used to define the shape of an object that is passed as an argument to the `index` function. It is defined in a file located at `../../../types.js`.\n\n2. What is the `processRepository` function and what does it do?\n- The `processRepository` function traverses a repository, calls LLMS for each file, and creates JSON files with the results. It takes in several arguments including the repository name, URL, root directory, output directory, and a list of files to ignore.\n\n3. What is the purpose of the `createVectorStore` function and what does it do?\n- The `createVectorStore` function creates vector files from markdown files. It takes in several arguments including the repository name, URL, root directory, output directory, and a list of files to ignore."
        },
        {
          "fileName": "processRepository.ts",
          "filePath": "src/cli/commands/index/processRepository.ts",
          "url": "https://github.com/context-labs/autodoc/blob/master/src/cli/commands/index/processRepository.ts",
          "summary": "The `processRepository` function is the main function of the `autodoc` project that processes a given repository and generates documentation for its code files. The function takes in an `AutodocRepoConfig` object that contains the configuration details for the repository to be processed, such as the repository name, URL, input and output root directories, and a list of files to ignore. The function also takes in an optional `dryRun` boolean flag that, when set to `true`, skips the actual processing and only estimates the number of files and folders in the repository.\n\nThe function first initializes an encoding for the GPT language model and an API rate limiter to control the number of API calls made to the OpenAI API. It then defines a `callLLM` function that takes in a prompt and an OpenAIChat model and returns a Promise that resolves to the generated text from the model's response to the prompt. The function also defines an `isModel` function that checks if a given LLMModelDetails object is not null.\n\nThe function then defines two sub-functions, `processFile` and `processFolder`, that respectively process a single code file and a folder of code files. The `processFile` function reads the content of a code file, generates a summary and a set of questions for the file using the `createCodeFileSummary` and `createCodeQuestions` functions, estimates the length of the generated text, selects the appropriate GPT language model based on the length, and calls the `callLLM` function to generate the summary and questions. The function then saves the generated summary and questions to a JSON file and updates the usage statistics of the selected language model. The `processFolder` function reads the summaries of all the code files in a folder, generates a summary for the folder using the `folderSummaryPrompt` function, and saves the generated summary to a JSON file.\n\nThe function then defines a `filesAndFolders` function that uses the `traverseFileSystem` function to recursively traverse the input root directory and count the number of files and folders in the repository. The function then calls the `traverseFileSystem` function twice, once to process all the code files in the repository using the `processFile` function, and once to process all the folders in the repository using the `processFolder` function.\n\nFinally, the function prints the usage statistics of the GPT language models and returns the `models` object. The `processRepository` function can be used as a standalone function to generate documentation for a single repository or as a part of a larger project that processes multiple repositories.",
          "questions": "1. What is the purpose of the `processRepository` function?\n- The `processRepository` function processes a repository by creating markdown files for each code file in the project and markdown summaries for each folder in the project, using OpenAI's language model to generate summaries and questions for each file.\n\n2. What is the role of the `traverseFileSystem` function in this code?\n- The `traverseFileSystem` function is used twice in this code to traverse the file system of the input and output directories, and process each file and folder by calling the appropriate function (`processFile` or `processFolder`) for each.\n\n3. What is the purpose of the `APIRateLimit` class?\n- The `APIRateLimit` class is used to limit the rate of API calls made to OpenAI's language model, ensuring that the code does not exceed the API's usage limits."
        },
        {
          "fileName": "prompts.ts",
          "filePath": "src/cli/commands/index/prompts.ts",
          "url": "https://github.com/context-labs/autodoc/blob/master/src/cli/commands/index/prompts.ts",
          "summary": "The code in this file provides three functions for generating prompts and documentation for a code documentation project called autodoc. \n\nThe first function, `createCodeFileSummary`, takes in a file path, project name, and file contents as arguments and returns a string that includes the project name, file path, and file contents. This function is likely used to generate a summary of a specific code file within the project, which can be used to provide context and documentation for that file.\n\nThe second function, `createCodeQuestions`, takes in the same arguments as `createCodeFileSummary` and returns a string that prompts the user to come up with three questions that a developer might have about the code in the file. This function is likely used to encourage critical thinking and analysis of the code, which can lead to more thorough documentation and understanding of the project.\n\nThe third function, `folderSummaryPrompt`, takes in a folder path, project name, an array of file summaries, and an array of folder summaries as arguments and returns a string that includes a summary of the contents of the folder, including the names and summaries of each file and subfolder. This function is likely used to generate a summary of a specific folder within the project, which can be used to provide context and documentation for the files and subfolders within that folder.\n\nOverall, these functions are useful for generating prompts and documentation for a code documentation project, which can help developers understand and navigate the project more easily. Here is an example of how `createCodeFileSummary` might be used:\n\n```\nconst filePath = 'src/components/Button.js';\nconst projectName = 'My Awesome Project';\nconst fileContents = `\n  import React from 'react';\n\n  const Button = ({ text, onClick }) => {\n    return (\n      <button onClick={onClick}>{text}</button>\n    );\n  };\n\n  export default Button;\n`;\n\nconst fileSummary = createCodeFileSummary(filePath, projectName, fileContents);\nconsole.log(fileSummary);\n```\n\nThis would output a string that includes the project name, file path, and file contents, which could be used as documentation for the `Button.js` file in the project.",
          "questions": "1. What is the purpose of the `createCodeFileSummary` function and what are its parameters?\n- The `createCodeFileSummary` function takes in a file path, project name, and file contents as parameters and returns a string that includes a prompt to write a technical explanation of the code in the file.\n2. What is the purpose of the `createCodeQuestions` function and what are its parameters?\n- The `createCodeQuestions` function takes in a file path, project name, and file contents as parameters and returns a string that includes a prompt to list 3 questions that a super smart developer might have about the code in the file.\n3. What is the purpose of the `folderSummaryPrompt` function and what are its parameters?\n- The `folderSummaryPrompt` function takes in a folder path, project name, an array of file summaries, and an array of folder summaries as parameters and returns a string that includes a prompt to write a technical explanation of the code in the files within the folder and how it fits into the larger project, as well as a summary of the contents of the subfolders."
        }
      ],
      "folders": [],
      "summary": "The code in this folder is responsible for generating documentation for a given repository using the Autodoc project. It processes the repository, converts JSON files to markdown, and creates a vector store for efficient similarity search between documents.\n\n`convertJsonToMarkdown.ts` contains the `convertJsonToMarkdown` function that converts JSON files to markdown files. It takes an object with properties `name`, `root`, and `output`. The function counts the number of files in the project, creates markdown files for each code file, and updates the spinner text to indicate progress. The markdown content includes a link to the file on GitHub, the summary, and any questions related to the file.\n\nExample usage:\n\n```typescript\nimport { convertJsonToMarkdown } from 'autodoc';\n\nconst config = {\n  name: 'my-repo',\n  root: '/path/to/my/repo',\n  output: '/path/to/output/directory',\n};\n\nconvertJsonToMarkdown(config);\n```\n\n`createVectorStore.ts` is responsible for creating a vector store for a set of documents. The input is a directory containing the documents to be indexed, and the output is a file containing the vector store. The code imports several modules from the `langchain` package and uses them to process the documents, generate embeddings, and create a vector store.\n\nExample usage:\n\n```typescript\nimport { createVectorStore } from 'autodoc';\n\nconst config = {\n  root: '/path/to/documents',\n  output: '/path/to/vectorstore.bin',\n};\n\ncreateVectorStore(config)\n  .then(() => console.log('Vector store created successfully'))\n  .catch((err) => console.error('Error creating vector store:', err));\n```\n\n`index.ts` serves as the entry point for generating documentation for a given repository. It sets up paths for JSON, markdown, and data directories, calls `processRepository` to traverse the repository and create JSON files, `convertJsonToMarkdown` to create markdown files, and `createVectorStore` to create vector files.\n\nExample usage:\n\n```typescript\nimport autodoc from 'autodoc';\n\nconst config = {\n  name: 'my-repo',\n  repositoryUrl: 'https://github.com/my-username/my-repo',\n  root: '/path/to/my/repo',\n  output: '/path/to/output/directory',\n  llms: true,\n  ignore: ['node_modules', 'dist'],\n};\n\nautodoc.index(config);\n```\n\n`processRepository.ts` contains the `processRepository` function that processes a given repository and generates documentation for its code files. It initializes an encoding for the GPT language model, defines sub-functions `processFile` and `processFolder`, and traverses the file system to process code files and folders.\n\n`prompts.ts` provides three functions for generating prompts and documentation for the Autodoc project: `createCodeFileSummary`, `createCodeQuestions`, and `folderSummaryPrompt`. These functions generate summaries and questions for code files and folders, which can be used to create more thorough documentation and understanding of the project.\n\nExample usage:\n\n```typescript\nimport { createCodeFileSummary } from 'autodoc';\n\nconst filePath = 'src/components/Button.js';\nconst projectName = 'My Awesome Project';\nconst fileContents = `\n  import React from 'react';\n\n  const Button = ({ text, onClick }) => {\n    return (\n      <button onClick={onClick}>{text}</button>\n    );\n  };\n\n  export default Button;\n`;\n\nconst fileSummary = createCodeFileSummary(filePath, projectName, fileContents);\nconsole.log(fileSummary);\n```\n\nOverall, this folder contains code that can be used to generate documentation for a given repository, which can help developers understand and navigate the project more easily.",
      "questions": ""
    },
    {
      "folderName": "init",
      "folderPath": ".autodoc/docs/json/src/cli/commands/init",
      "url": "https://github.com/context-labs/autodoc/tree/master/.autodoc/docs/json/src/cli/commands/init",
      "files": [
        {
          "fileName": "index.ts",
          "filePath": "src/cli/commands/init/index.ts",
          "url": "https://github.com/context-labs/autodoc/blob/master/src/cli/commands/init/index.ts",
          "summary": "The `autodoc` project is a tool for generating documentation for code repositories. This file contains two functions: `makeConfigTemplate` and `init`.\n\n`makeConfigTemplate` is a function that takes an optional `config` object as an argument and returns an `AutodocRepoConfig` object. If `config` is not provided, the function returns a default configuration object with the following properties:\n- `name`: an empty string\n- `repositoryUrl`: an empty string\n- `root`: the current directory\n- `output`: a directory named `.autodoc` in the current directory\n- `llms`: an array containing two LLM models (`GPT3` and `GPT4`)\n- `ignore`: an array of file patterns to ignore when generating documentation\n\n`init` is an asynchronous function that takes an optional `config` object as an argument and initializes the `autodoc` project. If `config` is not provided, `makeConfigTemplate` is called to generate a default configuration object. The function then checks if a `autodoc.config.json` file already exists in the root directory specified in the configuration object. If it does, the user is prompted to confirm whether they want to overwrite the existing configuration. If the user chooses not to continue, the function exits. If the user chooses to continue or if no configuration file exists, the user is prompted to enter the name and GitHub URL of their repository. The `makeConfigTemplate` function is then called with the new name and URL, and the resulting configuration object is written to a `autodoc.config.json` file in the root directory. Finally, a message is printed to the console indicating that `autodoc` has been initialized and providing instructions for generating documentation.\n\nThis file can be used in the larger `autodoc` project to provide default configuration options and to initialize the project with user-specified configuration options. For example, a user could run the following command to initialize `autodoc` with default options:\n```\nautodoc init\n```\nAlternatively, a user could run the following command to initialize `autodoc` with custom options:\n```\nautodoc init --name=my-repo --repositoryUrl=https://github.com/my-username/my-repo\n```",
          "questions": "1. What is the purpose of this code?\n- This code defines functions for initializing and creating a configuration template for the Autodoc project.\n\n2. What is the AutodocRepoConfig type and what properties does it have?\n- AutodocRepoConfig is a type defined in the `types.js` file, and it has properties for name, repositoryUrl, root, output, llms, and ignore.\n\n3. What is the purpose of the `init` function and what does it do?\n- The `init` function initializes the Autodoc project by prompting the user for repository information, creating a configuration file, and outputting a success message. If a configuration file already exists, it prompts the user to confirm overwriting it."
        }
      ],
      "folders": [],
      "summary": "The `index.ts` file in the `init` folder is responsible for initializing the `autodoc` project with user-specified or default configuration options. It contains two main functions: `makeConfigTemplate` and `init`.\n\n`makeConfigTemplate` is a utility function that generates an `AutodocRepoConfig` object based on the provided `config` object or default values. This function is useful for creating a configuration object that can be used throughout the `autodoc` project.\n\n`init` is the main function that initializes the `autodoc` project. It takes an optional `config` object as an argument and performs the following steps:\n\n1. If `config` is not provided, it calls `makeConfigTemplate` to generate a default configuration object.\n2. Checks if a `autodoc.config.json` file already exists in the root directory specified in the configuration object.\n3. If the file exists, prompts the user to confirm whether they want to overwrite the existing configuration.\n4. If the user chooses not to continue, the function exits.\n5. If the user chooses to continue or if no configuration file exists, prompts the user to enter the name and GitHub URL of their repository.\n6. Calls `makeConfigTemplate` with the new name and URL, and writes the resulting configuration object to a `autodoc.config.json` file in the root directory.\n7. Prints a message to the console indicating that `autodoc` has been initialized and provides instructions for generating documentation.\n\nThis file plays a crucial role in the `autodoc` project by providing a way to initialize the project with user-specified or default configuration options. It can be used in conjunction with other parts of the project to generate documentation based on the provided configuration.\n\nFor example, a user could initialize `autodoc` with default options by running the following command:\n\n```bash\nautodoc init\n```\n\nAlternatively, a user could initialize `autodoc` with custom options by running the following command:\n\n```bash\nautodoc init --name=my-repo --repositoryUrl=https://github.com/my-username/my-repo\n```\n\nIn summary, the `index.ts` file in the `init` folder is an essential part of the `autodoc` project, providing a way to initialize the project with user-specified or default configuration options. It works in conjunction with other parts of the project to generate documentation based on the provided configuration.",
      "questions": ""
    },
    {
      "folderName": "query",
      "folderPath": ".autodoc/docs/json/src/cli/commands/query",
      "url": "https://github.com/context-labs/autodoc/tree/master/.autodoc/docs/json/src/cli/commands/query",
      "files": [
        {
          "fileName": "createChatChain.ts",
          "filePath": "src/cli/commands/query/createChatChain.ts",
          "url": "https://github.com/context-labs/autodoc/blob/master/src/cli/commands/query/createChatChain.ts",
          "summary": "The `makeChain` function in the `autodoc` project is responsible for creating a chatbot that can answer technical questions related to a software project. The chatbot is designed to be an AI assistant for a software project and is trained on all the code that makes up the project. The chatbot is created using several libraries and models, including `langchain/llms`, `langchain/chains`, `langchain/prompts`, `langchain/hnswlib.js`, and `types.js`.\n\nThe `makeChain` function takes several parameters, including the name of the project, the URL of the project's repository, a vector store, an array of LLM models, and an optional callback function. The function first selects an LLM model to use for generating responses. If there are multiple LLM models provided, it selects the second one if it exists, otherwise it selects the first one. \n\nThe function then creates a `questionGenerator` object using the selected LLM model and a `CONDENSE_PROMPT` template. The `CONDENSE_PROMPT` template is used to rephrase a follow-up question to be a standalone question. \n\nNext, the function creates a `QA_PROMPT` template using the `makeQAPrompt` function. The `QA_PROMPT` template is used to provide a conversational answer with hyperlinks back to GitHub. The template includes instructions for the chatbot on how to answer questions, including how to use the context to inform the answer and how to handle questions that are not related to the project.\n\nFinally, the function creates a `ChatVectorDBQAChain` object using the vector store, the `questionGenerator` object, and a `docChain` object. The `docChain` object is created using the `loadQAChain` function and an `OpenAIChat` object. The `OpenAIChat` object is used to generate responses to questions using the LLM model and the `QA_PROMPT` template. \n\nOverall, the `makeChain` function is a key component of the `autodoc` project, as it creates a chatbot that can answer technical questions related to a software project. The chatbot is designed to be an AI assistant for a software project and is trained on all the code that makes up the project. The chatbot is created using several libraries and models, including `langchain/llms`, `langchain/chains`, `langchain/prompts`, `langchain/hnswlib.js`, and `types.js`.",
          "questions": "1. What is the purpose of the `autodoc` project and how does this code fit into it?\n- The code in this file is used to create a chatbot that can answer technical questions about a software project called `projectName`, using a combination of GPT-3 or GPT-4 and a vector database. The `autodoc` project likely involves automatically generating documentation for software projects.\n2. What is the significance of the `HNSWLib` and `LLMModels` imports?\n- The `HNSWLib` import is used to create a vector database for the chatbot to search through, while the `LLMModels` import is used to specify which language model to use for generating responses. \n3. What is the purpose of the `makeQAPrompt` function?\n- The `makeQAPrompt` function creates a prompt template that the chatbot will use to generate responses to questions about the `projectName` software project. The template includes instructions for how the response should be structured and what information it should include."
        },
        {
          "fileName": "index.ts",
          "filePath": "src/cli/commands/query/index.ts",
          "url": "https://github.com/context-labs/autodoc/blob/master/src/cli/commands/query/index.ts",
          "summary": "The `query` function in this file is a chatbot that can answer questions related to a codebase. It takes in two arguments: `AutodocRepoConfig` and `AutodocUserConfig`. The `AutodocRepoConfig` object contains information about the repository, such as the name and URL, while the `AutodocUserConfig` object contains information about the user, such as their preferred language model. \n\nThe chatbot uses the `inquirer` package to prompt the user for a question related to the codebase. It then uses the `makeChain` function from the `createChatChain.js` file to generate a response to the question. The `makeChain` function takes in the name of the repository, the repository URL, a vector store, a language model, and a callback function. It returns a function that can be called with a question and chat history, and it generates a response to the question using the vector store and language model.\n\nThe chatbot displays the response to the user using the `marked` package to format the response as Markdown. It also keeps track of the chat history in an array called `chatHistory`.\n\nThe chatbot runs in a loop until the user types \"exit\". It prompts the user for a question, generates a response, displays the response, and repeats until the user types \"exit\".\n\nThis chatbot can be used as a tool to help users understand a codebase. It uses natural language processing to generate responses to questions, and it can be customized with different language models and vector stores. It also keeps track of chat history, which can be useful for debugging or improving the chatbot's responses over time. \n\nExample usage:\n\n```\nimport { query } from 'autodoc';\n\nconst repoConfig = {\n  name: 'my-project',\n  repositoryUrl: 'https://github.com/my-username/my-project',\n  output: '/path/to/output',\n};\n\nconst userConfig = {\n  llms: 'en',\n};\n\nquery(repoConfig, userConfig);\n```\n\nThis will start the chatbot for the `my-project` repository using the English language model. The user can then ask questions related to the codebase, and the chatbot will generate responses.",
          "questions": "1. What is the purpose of the `query` function?\n- The `query` function is used to run a chatbot that can answer questions related to a codebase.\n\n2. What is the `vectorStore` variable used for?\n- The `vectorStore` variable is used to store and load embeddings for the chatbot.\n\n3. What is the purpose of the `chatHistory` array?\n- The `chatHistory` array is used to keep track of the chat history between the user and the chatbot."
        }
      ],
      "folders": [],
      "summary": "The `query` folder in the `autodoc` project contains code for creating a chatbot that can answer technical questions related to a software project. The chatbot is designed to be an AI assistant for a software project and is trained on all the code that makes up the project.\n\nThe main file in this folder is `index.ts`, which exports a `query` function. This function takes two arguments: `AutodocRepoConfig` and `AutodocUserConfig`. The `AutodocRepoConfig` object contains information about the repository, such as the name and URL, while the `AutodocUserConfig` object contains information about the user, such as their preferred language model.\n\nThe chatbot uses the `inquirer` package to prompt the user for a question related to the codebase. It then uses the `makeChain` function from the `createChatChain.ts` file to generate a response to the question. The `makeChain` function takes in the name of the repository, the repository URL, a vector store, a language model, and a callback function. It returns a function that can be called with a question and chat history, and it generates a response to the question using the vector store and language model.\n\nThe chatbot displays the response to the user using the `marked` package to format the response as Markdown. It also keeps track of the chat history in an array called `chatHistory`.\n\nThe chatbot runs in a loop until the user types \"exit\". It prompts the user for a question, generates a response, displays the response, and repeats until the user types \"exit\".\n\nExample usage:\n\n```javascript\nimport { query } from 'autodoc';\n\nconst repoConfig = {\n  name: 'my-project',\n  repositoryUrl: 'https://github.com/my-username/my-project',\n  output: '/path/to/output',\n};\n\nconst userConfig = {\n  llms: 'en',\n};\n\nquery(repoConfig, userConfig);\n```\n\nThis will start the chatbot for the `my-project` repository using the English language model. The user can then ask questions related to the codebase, and the chatbot will generate responses.\n\nThe `createChatChain.ts` file contains the `makeChain` function, which is responsible for creating the chatbot. It uses several libraries and models, including `langchain/llms`, `langchain/chains`, `langchain/prompts`, `langchain/hnswlib.js`, and `types.js`. The function creates a `ChatVectorDBQAChain` object using the vector store, a `questionGenerator` object, and a `docChain` object. The `docChain` object is created using the `loadQAChain` function and an `OpenAIChat` object, which is used to generate responses to questions using the LLM model and a `QA_PROMPT` template.",
      "questions": ""
    },
    {
      "folderName": "user",
      "folderPath": ".autodoc/docs/json/src/cli/commands/user",
      "url": "https://github.com/context-labs/autodoc/tree/master/.autodoc/docs/json/src/cli/commands/user",
      "files": [
        {
          "fileName": "index.ts",
          "filePath": "src/cli/commands/user/index.ts",
          "url": "https://github.com/context-labs/autodoc/blob/master/src/cli/commands/user/index.ts",
          "summary": "The `autodoc` project is a tool for generating documentation from code. This file contains code for handling user configuration of the tool. \n\nThe `makeConfigTemplate` function takes an optional `config` object and returns a new `AutodocUserConfig` object. If `config` is provided, the `llms` property of the new object is set to the value of `config.llms`. Otherwise, the `llms` property is set to an array containing the `LLMModels.GPT3` value.\n\nThe `user` function is an asynchronous function that takes an optional `config` object as an argument. If a user configuration file already exists at `userConfigFilePath`, the function prompts the user to confirm whether they want to overwrite the existing file. If the user chooses not to continue, the function exits. Otherwise, the function creates the directory containing the configuration file if it does not already exist.\n\nThe function then prompts the user to select which LLMs they have access to using the `inquirer` library. The choices are presented as a list of options, each with a name and a value. The `llms` property of the `config` object is set to the selected value.\n\nThe `newConfig` object is created by calling `makeConfigTemplate` with the updated `llms` property and the rest of the properties from the original `config` object. The `newConfig` object is then written to the user configuration file using the `fs` library.\n\nFinally, a success message is printed to the console.\n\nThis code can be used to handle user configuration of the `autodoc` tool. The `makeConfigTemplate` function can be used to create a default configuration object, and the `user` function can be called to prompt the user to select which LLMs they have access to and write the resulting configuration to a file. The `userConfigFilePath` and `userConfigFileName` constants are used to specify the location and name of the configuration file, respectively.",
          "questions": "1. What is the purpose of the `makeConfigTemplate` function?\n- The `makeConfigTemplate` function returns an `AutodocUserConfig` object with default values for the `llms` property, and accepts an optional `config` parameter to override the default values.\n\n2. What is the purpose of the `user` function?\n- The `user` function prompts the user to select which LLMs they have access to, creates a new `AutodocUserConfig` object with the selected LLMs, and saves it to a JSON file at `userConfigFilePath`.\n\n3. What is the purpose of the `const.js` and `types.js` files?\n- The `const.js` file exports the `userConfigFileName` and `userConfigFilePath` constants used in the `user` function, while the `types.js` file exports the `AutodocUserConfig` and `LLMModels` types used throughout the `autodoc` project."
        }
      ],
      "folders": [],
      "summary": "The `index.ts` file in the `user` folder is responsible for handling user configuration of the `autodoc` tool. It provides two main functions: `makeConfigTemplate` and `user`.\n\nThe `makeConfigTemplate` function is used to create a default configuration object called `AutodocUserConfig`. It takes an optional `config` object as an argument. If `config` is provided, the `llms` property of the new object is set to the value of `config.llms`. Otherwise, the `llms` property is set to an array containing the `LLMModels.GPT3` value.\n\n```typescript\nfunction makeConfigTemplate(config?: Partial<AutodocUserConfig>): AutodocUserConfig {\n  // ...\n}\n```\n\nThe `user` function is an asynchronous function that takes an optional `config` object as an argument. It is responsible for prompting the user to select which LLMs they have access to and writing the resulting configuration to a file. The `userConfigFilePath` and `userConfigFileName` constants are used to specify the location and name of the configuration file, respectively.\n\n```typescript\nasync function user(config?: Partial<AutodocUserConfig>): Promise<void> {\n  // ...\n}\n```\n\nThe `user` function first checks if a user configuration file already exists at `userConfigFilePath`. If it does, the function prompts the user to confirm whether they want to overwrite the existing file. If the user chooses not to continue, the function exits. Otherwise, the function creates the directory containing the configuration file if it does not already exist.\n\nNext, the function prompts the user to select which LLMs they have access to using the `inquirer` library. The choices are presented as a list of options, each with a name and a value. The `llms` property of the `config` object is set to the selected value.\n\n```typescript\nconst { llms } = await inquirer.prompt([\n  {\n    type: \"list\",\n    name: \"llms\",\n    message: \"Which LLMs do you have access to?\",\n    choices: [\n      // ...\n    ],\n  },\n]);\n```\n\nThe `newConfig` object is created by calling `makeConfigTemplate` with the updated `llms` property and the rest of the properties from the original `config` object. The `newConfig` object is then written to the user configuration file using the `fs` library.\n\n```typescript\nconst newConfig = makeConfigTemplate({ ...config, llms });\nfs.writeFileSync(userConfigFilePath, JSON.stringify(newConfig, null, 2));\n```\n\nFinally, a success message is printed to the console.\n\nThis code is essential for configuring the `autodoc` tool based on the user's preferences and available LLMs. The `makeConfigTemplate` function can be used to create a default configuration object, while the `user` function can be called to prompt the user to select which LLMs they have access to and write the resulting configuration to a file.",
      "questions": ""
    }
  ],
  "summary": "The `src/cli/commands` folder contains code for various command-line interface (CLI) commands used in the Autodoc project. These commands help users interact with the project, such as initializing configurations, generating documentation, and querying the generated documentation.\n\n### estimate\n\nThe `estimate` command estimates the cost of indexing a given repository within the Autodoc project. It takes an object with properties such as the repository name, URL, root directory, output directory, and optional parameters.\n\n```javascript\nimport { estimate } from 'autodoc';\n\nestimate({\n  name: 'my-repo',\n  repositoryUrl: 'https://github.com/my-username/my-repo.git',\n  root: '/path/to/repo',\n  output: '/path/to/output',\n  llms: true,\n  ignore: ['node_modules', 'dist'],\n});\n```\n\n### index\n\nThe `index` command generates documentation for a given repository using the Autodoc project. It processes the repository, converts JSON files to markdown, and creates a vector store for efficient similarity search between documents.\n\n```typescript\nimport autodoc from 'autodoc';\n\nconst config = {\n  name: 'my-repo',\n  repositoryUrl: 'https://github.com/my-username/my-repo',\n  root: '/path/to/my/repo',\n  output: '/path/to/output/directory',\n  llms: true,\n  ignore: ['node_modules', 'dist'],\n};\n\nautodoc.index(config);\n```\n\n### init\n\nThe `init` command initializes the Autodoc project with user-specified or default configuration options.\n\n```bash\nautodoc init\n```\n\nOr with custom options:\n\n```bash\nautodoc init --name=my-repo --repositoryUrl=https://github.com/my-username/my-repo\n```\n\n### query\n\nThe `query` command creates a chatbot that can answer technical questions related to a software project. The chatbot is designed to be an AI assistant for a software project and is trained on all the code that makes up the project.\n\n```javascript\nimport { query } from 'autodoc';\n\nconst repoConfig = {\n  name: 'my-project',\n  repositoryUrl: 'https://github.com/my-username/my-project',\n  output: '/path/to/output',\n};\n\nconst userConfig = {\n  llms: 'en',\n};\n\nquery(repoConfig, userConfig);\n```\n\n### user\n\nThe `user` command handles user configuration of the Autodoc tool. It prompts the user to select which LLMs they have access to and writes the resulting configuration to a file.\n\n```javascript\nimport { user } from 'autodoc';\n\nconst config = {\n  llms: 'en',\n};\n\nuser(config);\n```\n\nIn summary, the `src/cli/commands` folder contains code for various CLI commands that help users interact with the Autodoc project. These commands provide functionality such as initializing configurations, generating documentation, querying the generated documentation, and handling user configurations.",
  "questions": ""
}